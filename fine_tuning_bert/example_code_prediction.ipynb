{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWsxDTxjj5Kh"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRkIpxofkW1t"
      },
      "source": [
        "!cp /content/gdrive/bertfunss.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5rdw73Uk7qM"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh87mz6FjSUu"
      },
      "source": [
        "import bertfunss\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import pandas as pd\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXOcvGS-jl7t"
      },
      "source": [
        "#get the gpu device\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER24UGIJlW6S"
      },
      "source": [
        "#see if the gpu is available\n",
        "if torch.cuda.is_available():    \n",
        "    #tell pytorch to use the gpu    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GnVqdzUjbaJ"
      },
      "source": [
        "#load the data for prediction\n",
        "df = pd.read_csv('pred_data.csv')\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFMlJozfsoI1"
      },
      "source": [
        "###Formality\n",
        "model = BertForSequenceClassification.from_pretrained('formality_model')\n",
        "tokenizer = BertTokenizer.from_pretrained('formality_model')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNOx0KR0c2pt"
      },
      "source": [
        "sentences = df.sen_coding.values\n",
        "sentences[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kZooej3s56J"
      },
      "source": [
        "y_for = bertfunss.modelinuse(sentences, None, tokenizer, model, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWJV472qNnof"
      },
      "source": [
        "y_for[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-VXyWbUgfHj"
      },
      "source": [
        "###Factuality\n",
        "model = BertForSequenceClassification.from_pretrained('factuality_model')\n",
        "tokenizer = BertTokenizer.from_pretrained('factuality_model')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5q4um_0grGN"
      },
      "source": [
        "y_fact = bertfunss.modelinuse(sentences, None, tokenizer, model, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16YebdS9KaH8"
      },
      "source": [
        "y_fact[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFvvCrNagTwp"
      },
      "source": [
        "#output the results\n",
        "outputdf = pd.DataFrame({'id': df['sen_id'], 'sub_id': df['sub_id'], 'sen': sentences, 'y_for': y_for, 'y_fact': y_fact})\n",
        "outputdf[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46OwC0cBSUj_"
      },
      "source": [
        "outputdf.to_csv(r'pred_data_output.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}